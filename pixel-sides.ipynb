{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "443821c7-c7fb-4fb8-8e8d-3d44ade75de9",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![Avatar foto de Flávio Coutinho](https://fegemo.github.io/cefet-front-end/images/flavio-avatar.jpg)\n",
    "# Projeto: Pixel Sides\n",
    "\n",
    "\n",
    "<dl style=\"margin-top: 1.5em\">\n",
    "    <dt>Aluno</dt><dd>Flávio Coutinho &lt;<a href=\"mailto:fegemo@cefetmg.br\">fegemo@cefetmg.br</a>&gt;</dd>\n",
    "    <dt>Turma</dt><dd>Aprendizado de Máquina, UFMG, 01/21</dd>\n",
    "    <dt>Objetivo</dt><dd>Explorar algoritmos de Aprendizado de Máquina na geração procedural de conteúdo para jogos.</dd>\n",
    "    <dt>Link</dt><dd><a href=\"https://fegemo.github.io/pixel-sides/\" target=\"_blank\">https://fegemo.github.io/pixel-sides/</a>\n",
    "    <dt>Vídeo</dt><dd><a href=\"https://youtu.be/1r4YDKAaCew\" target=\"_blank\">no YouTube</a>\n",
    "</dl>\n",
    "\n",
    "Conteúdo deste _notebook_:\n",
    "- [Descrição do Projeto](#Descrição-do-Projeto)\n",
    "- [Extração de Sprites](#Extração-de-Sprites)\n",
    "- [Classificador de Pose](#Classificador-de-Pose)\n",
    "- [Geração de Sprite com DCGAN](#Geração-de-Sprite-com-DCGAN)\n",
    "- [Geração de um Lado dado Outro](#Geração-de-um-Lado-dado-Outro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16fa88a3-dee2-4209-a22f-aa61df6efc93",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>@import url('https://fonts.googleapis.com/css2?family=Bitter&family=Titillium+Web:wght@300&display=swap');\n",
       "\n",
       "html,\n",
       "#notebook {\n",
       "    scroll-behavior: smooth;\n",
       "}\n",
       "\n",
       "body {\n",
       "    font-family: 'Bitter', serif;\n",
       "}\n",
       "\n",
       "h1, h2, h3, h4, h5, h6 {\n",
       "    font-family: 'Titillium Web', sans-serif;\n",
       "}\n",
       "\n",
       "dl {\n",
       "    display: grid;\n",
       "    grid-template-columns: auto 1fr;\n",
       "    gap: 0.25em 1em;\n",
       "}\n",
       "\n",
       "dt {\n",
       "    grid-column: 1 / 2;\n",
       "}\n",
       "\n",
       "dd {\n",
       "    grid-column: 2 / 3;\n",
       "}\n",
       "\n",
       "/* Estilos do primeiro parÃ¡grafo (contÃ©m img avatar) da primeira cÃ©lula HTML */\n",
       "#MathJax_Message + .jp-Cell-inputWrapper:nth-of-type(2) p:first-of-type,\n",
       ".jp-Cell.jp-mod-rendered:first-of-type p:first-of-type,\n",
       ".text_cell.rendered:first-of-type p:first-of-type {\n",
       "    float: right;\n",
       "    max-width: 150px;\n",
       "}\n",
       "\n",
       "img[alt^=\"Avatar\"] {\n",
       "    float: right;\n",
       "    border-radius: 50%;\n",
       "    max-width: 100%;\n",
       "    shape-outside: circle(50%);\n",
       "    animation: breething 5s ease-in-out 0s infinite alternate;\n",
       "    position: relative;\n",
       "}\n",
       "\n",
       "#MathJax_Message + .jp-Cell-inputWrapper:nth-of-type(2) p:first-of-type:hover img[alt^=\"Avatar\"],\n",
       ".jp-Cell.jp-mod-rendered:first-of-type p:first-of-type:hover img[alt^=\"Avatar\"],\n",
       ".text_cell.rendered:first-of-type p:first-of-type:hover img[alt^=\"Avatar\"] {\n",
       "    transform-origin: center bottom;\n",
       "    animation: rotating 1s ease-in-out 0s 1,\n",
       "        jumping-up 0.1s ease-out 0.6s 1,\n",
       "        falling-down 0.1s ease-in 0.7s 1,\n",
       "        flattening 0.2s ease-out 0.8s 1; \n",
       "}\n",
       "\n",
       "@keyframes breething {\n",
       "    from { transform: scale(1) }\n",
       "    to { transform: scale(0.975) }\n",
       "}\n",
       "\n",
       "@keyframes rotating {\n",
       "    from { transform: rotateY(0) }\n",
       "    to { transform: rotateY(3turn) }\n",
       "}\n",
       "\n",
       "@keyframes jumping-up {\n",
       "    from { top: 0 }\n",
       "    to { top: -200px }\n",
       "}\n",
       "\n",
       "@keyframes falling-down {\n",
       "    from { top: -200px }\n",
       "    to { top: 0 }\n",
       "}\n",
       "\n",
       "@keyframes flattening {\n",
       "    0% { \n",
       "        transform: scaleY(0.8) scaleX(1.2);\n",
       "    }\n",
       "    33% {\n",
       "        transform: scaleY(1.1) scaleX(0.9);\n",
       "    }\n",
       "    67% {\n",
       "        transform: scaleY(0.95) scaleX(1.05);\n",
       "    }\n",
       "    100% {\n",
       "        transform: scale(1);\n",
       "    }\n",
       "}\n",
       "\n",
       ".jp-Cell.jp-mod-rendered .jp-RenderedMarkdown > h2,\n",
       ".text_cell.rendered .rendered_html > h2 {\n",
       "    border-bottom: 3px solid black;\n",
       "    padding-bottom: 0.25em;\n",
       "}\n",
       "\n",
       "/* Estilos da primeira cÃ©lula HTML */\n",
       "#MathJax_Message + .jp-Cell-inputWrapper:nth-of-type(2),\n",
       ".jp-Cell.jp-mod-rendered:first-of-type,\n",
       ".text_cell.rendered:first-of-type {\n",
       "    position: relative;\n",
       "    overflow: hidden;\n",
       "}\n",
       "\n",
       "#MathJax_Message + .jp-Cell-inputWrapper:nth-of-type(2)::before,\n",
       ".jp-Cell.jp-mod-rendered:first-of-type::before,\n",
       ".text_cell.rendered:first-of-type::before {\n",
       "    content: \"\";\n",
       "    display: block;\n",
       "    position: absolute;\n",
       "    --blur-size: 0px;\n",
       "    top: calc(-3 * var(--blur-size));\n",
       "    right: calc(-3 * var(--blur-size));\n",
       "    bottom: calc(-3 * var(--blur-size));\n",
       "    left: calc(-3 * var(--blur-size));\n",
       "    pointer-events: none;\n",
       "    background-image: linear-gradient(45deg, #000000, #00b6ec), url(https://wallpaperaccess.com/full/869.jpg);\n",
       "    background-position: center;\n",
       "    filter: blur(var(--blur-size)) brightness(0.8);\n",
       "    background-blend-mode: hard-light;\n",
       "}\n",
       "\n",
       "#MathJax_Message + .jp-Cell-inputWrapper:nth-of-type(2)::before {\n",
       "    z-index: -1;\n",
       "}\n",
       "\n",
       "#MathJax_Message + .jp-Cell-inputWrapper:nth-of-type(2) .jp-RenderedMarkdown,\n",
       ".jp-Cell.jp-mod-rendered:first-of-type .jp-RenderedMarkdown,\n",
       ".text_cell.rendered:first-of-type .rendered_html {\n",
       "    color: white;\n",
       "}\n",
       "\n",
       "#MathJax_Message + .jp-Cell-inputWrapper:nth-of-type(2) .jp-RenderedMarkdown a:link,\n",
       ".jp-Cell.jp-mod-rendered:first-of-type .jp-RenderedMarkdown a:link,\n",
       ".text_cell.rendered:first-of-type .rendered_html a:link {\n",
       "    color: #3ea6ff;\n",
       "    text-decoration: none;\n",
       "}\n",
       "\n",
       "#MathJax_Message + .jp-Cell-inputWrapper:nth-of-type(2) .jp-RenderedMarkdown a:visited,\n",
       ".jp-Cell.jp-mod-rendered:first-of-type .jp-RenderedMarkdown a:visited,\n",
       ".text_cell.rendered:first-of-type .rendered_html a:visited {\n",
       "    color: #09ee42;\n",
       "}\n",
       "\n",
       "#MathJax_Message + .jp-Cell-inputWrapper:nth-of-type(2) .jp-RenderedMarkdown a:hover,\n",
       ".jp-Cell.jp-mod-rendered:first-of-type .jp-RenderedMarkdown a:hover,\n",
       ".text_cell.rendered:first-of-type .rendered_html a:hover {\n",
       "    background-color: #fff1;\n",
       "}\n",
       "\n",
       "#MathJax_Message + .jp-Cell-inputWrapper:nth-of-type(2) .jp-RenderedMarkdown ul,\n",
       ".jp-Cell.jp-mod-rendered:first-of-type ul,\n",
       ".text_cell.rendered:first-of-type ul {\n",
       "    display: flex;\n",
       "    list-style-type: none;\n",
       "    padding-left: 0;\n",
       "    gap: 0.5em;\n",
       "    text-align: center;\n",
       "}\n",
       "\n",
       "#MathJax_Message + .jp-Cell-inputWrapper:nth-of-type(2) .jp-RenderedMarkdown ul > li > a,\n",
       ".jp-Cell.jp-mod-rendered:first-of-type ul > li > a,\n",
       ".text_cell.rendered:first-of-type ul > li > a {\n",
       "    display: block;\n",
       "    border: 3px double #ffffff40;\n",
       "    border-radius: 5px;\n",
       "    padding: 0.25em 1em;\n",
       "}\n",
       "\n",
       "#MathJax_Message + .jp-Cell-inputWrapper:nth-of-type(2) .jp-RenderedMarkdown ul > li > ul,\n",
       ".jp-Cell.jp-mod-rendered:first-of-type ul > li > ul,\n",
       ".text_cell.rendered:first-of-type ul > li > ul {\n",
       "    opacity: 0;\n",
       "    text-align: left;\n",
       "    flex-direction: column;\n",
       "}\n",
       "\n",
       "#MathJax_Message + .jp-Cell-inputWrapper:nth-of-type(2) .jp-RenderedMarkdown ul > li > ul > li > a,\n",
       ".jp-Cell.jp-mod-rendered:first-of-type ul > li > ul > li > a,\n",
       ".text_cell.rendered:first-of-type ul > li > ul > li > a {\n",
       "    border-width: 0 0 3px 0;\n",
       "    gap: 0;\n",
       "    border-radius: 0;\n",
       "    padding: 0.25em 1em;\n",
       "}\n",
       "\n",
       "#MathJax_Message + .jp-Cell-inputWrapper:nth-of-type(2) .jp-RenderedMarkdown ul > li:hover > ul,\n",
       ".jp-Cell.jp-mod-rendered:first-of-type ul > li:hover > ul,\n",
       ".text_cell.rendered:first-of-type ul > li:hover > ul {\n",
       "    opacity: 1;\n",
       "}\n",
       "\n",
       "img[alt*=\"center\"] {\n",
       "    display: block;\n",
       "    margin-left: auto;\n",
       "    margin-right: auto;\n",
       "}\n",
       "\n",
       "img[alt*=\"maxw300\"] {\n",
       "    max-width: 300px;\n",
       "}\n",
       "\n",
       "img[alt*=\"maxw600\"] {\n",
       "    max-width: 600px;\n",
       "}\n",
       "\n",
       "img[alt*=\"maxw700\"] {\n",
       "    max-width: 700px;\n",
       "}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Define uma folha de estilos pro notebook\n",
    "\"\"\"\n",
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = \"<style>\" + open(\"./estilos.css\", \"r\").read() + \"</style>\"\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dcc916-caf1-4dab-a79a-d972d9aae6c1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Descrição do Projeto\n",
    "\n",
    "Este é um projeto para a disciplina de Aprendizado de Máquina do DCC/UFMG em 2021/1, ministrada por Adriano Veloso.\n",
    "O objetivo é **estudar o uso de algoritmos de aprendizado para a geração de conteúdo procedural para jogos**.\n",
    "Neste momento, focou-se em imagens de personagens em _pixel art_.\n",
    "\n",
    "Foi usado o _dataset_ [TinyHero](https://www.kaggle.com/calmness/retro-pixel-characters-generator/), que é composto\n",
    "por $3648$ arquivos de imagem $(64, 64, 4)$ divididos em $4$ classes, cada uma representando uma direção\n",
    "para onde o personagem está virado.\n",
    "\n",
    "![centermaxw600](docs/images/tiny-hero-sides.png)\n",
    "\n",
    "Os estudos desenvolvidos neste projeto contemplaram uso de redes convolucionais para classificação, geração de novas \n",
    "imagens usando redes adversariais convolucionais e a geração da pose de um personagem (direita) dada apenas uma única \n",
    "imagem em outra pose (de frente). Também foi feita uma rotina para extrair mais imagens (além do TinyHero) a partir\n",
    "do software RPG Maker 2000.\n",
    "\n",
    "O que foi desenvolvido:\n",
    "\n",
    "0. Coletando imagens do RPG Maker\n",
    "1. Classificador de pose\n",
    "2. Gerando novos personagens com uma DCGAN\n",
    "3. Gerando sprites laterais com Pix2Pix\n",
    "\n",
    "Este _notebook_ mostra apenas os principais resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255371e6-cc61-4563-87c8-f8b3c11341eb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Extração de Sprites\n",
    "\n",
    "O _notebook_ [00-pick-images-from-rpgmaker.ipynb](00-pick-images-from-rpgmaker.ipynb) contém o código para gerar\n",
    "um novo _dataset_ de imagens de personagens em _pixel art_ em $4$ direções. Foram geradas $96$ imagens de $(64, 64, 4)$\n",
    "divididas nas $4$ classes.\n",
    "\n",
    "![centermaxw300](docs/images/rpgmaker-examples.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767062e3-443d-42a6-a8b3-70ccf2a67ff4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Esse _minidataset_ foi gerado para avaliar o classificador de poses que foi treinado apenas com os dados do _dataset_ TinyHero pra\n",
    "verificar o impacto de ter uma distribuição de dados distinta do momento de teste e do de validação. E o resultado foi terrível,\n",
    "conforme esperado :). Isso será descrito no próximo experimento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a697949d-4696-4926-bbb0-1268a6822f29",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Classificador de Pose\n",
    "\n",
    "Veja o _notebook_ [01-pose-classifier-cnn.ipynb](01-pose-classifier-cnn.ipynb) para ver a implementação.\n",
    "Neste experimento foi desenvolvido um **classificador CNN para estimar a pose** da imagem de um personagem.\n",
    "A rede gerada possui a seguinte arquitetura:\n",
    "\n",
    "![center](docs/images/pose-classifier-diagram.svg)\n",
    "\n",
    "Há 2 sequências de convolução e _max pooling_, seguidas de duas camadas totalmente conectadas. A última tem ativação _softmax_\n",
    "com 4 saídas e indica a confiança do modelo na classificação de cada exemplo quanto às 4 classes (costas, esquerda, frente, direita).\n",
    "Ao todo foram menos de $25.000$ parâmetros treináveis.\n",
    "\n",
    "O treinamento e validação foram feitos no _dataset_ TinyHero em proporção 80/20%:\n",
    "\n",
    "![centermaxw300](docs/images/tiny-hero-examples.png)\n",
    "\n",
    "Em apenas 10 épocas a rede foi capaz de atingir **acurácia bem próxima de $100%$** no _dataset_ TinyHero, com o qual foi treinada:\n",
    "\n",
    "![centermaxw600](docs/images/resultado-classificador-pose.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca01edb-29e9-4c7d-9b18-9e8059449298",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Como um pequeno teste, após ter sido treinada em TinyHero, a rede foi avaliada para classificar o _minidataset_ \n",
    "gerado pela coleta de imagens do RPG Maker 2000 (descrito no passo anterior). Ele possui apenas $96$ imagens\n",
    "e, apesar de ter sido fornecido à rede com um formato idêntico ao TinyHero $(64, 64, 4)$, originalmente suas\n",
    "imagens tinham $(32, 24, 4)$. Além disso, o estilo artístico é um pouco diferente se comparado ao TinyHero.\n",
    "\n",
    "Ao fazer a previsão das $96$ imagens quanto a suas poses, os resultados não foram satisfatórios:\n",
    "\n",
    "![centermaxw700](docs/images/resultado-classificador-rpgmaker.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189079a2-2a58-430f-8f6c-ec201608b4f9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Tanto os exemplos de previsão quanto a matriz de confusão dão ideia dos acertos e erros do classificador nesse _dataset_.\n",
    "\n",
    "Isso é explicado pelo fato de que a distribuição das imagens no conjunto de treinamento foi radicalmente diferente\n",
    "da distribuição nesse teste com outro _dataset_.\n",
    "\n",
    "Ainda assim, é interessante notar que houve vários acertos apesar do classificador nunca ter visto nenhuma das\n",
    "imagens do RPG Maker.\n",
    "\n",
    "\n",
    "Em casos assim, é importante:\n",
    "\n",
    "1. Fazer o _dataset_ de treino conter uma distribuição parecida com a do teste\n",
    "1. Ter mais dados disponíveis do segundo _dataset_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8765f748-3eb8-47b3-9faa-2b7880592c8e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Geração de Sprite com DCGAN\n",
    "\n",
    "O terceiro experimento pode ser visto no _notebook_ [02-generate-new-sprite.ipynb](02-generate-new-sprite.ipynb).\n",
    "O objetivo foi de treinar uma DCGAN no conjunto de dados TinyHero para gerar novas imagens de personagens\n",
    "em _pixel art_ nessas $4$ direções.\n",
    "\n",
    "A rede generativa adversarial convolucional profunda (DCGAN) é dividida em uma rede geradora e outra discriminativa\n",
    "que competem e evoluem em prol de possibilitar que a geradora consiga produzir imagens semelhantes às do treinamento.\n",
    "\n",
    "Ambas redes foram relativamente rasas, com ~3 camadas e foram treinadas ao longo de $250$ épocas. Os resultados\n",
    "não foram muito satisfatórios, conforme pode ser visto no resultado final:\n",
    "\n",
    "![center](docs/images/dcgan-250.png)\n",
    "\n",
    "Do ponto de vista da competição entre gerador e discriminador, seus erros ao longo das épocas evoluíram da seguinte forma:\n",
    "\n",
    "![centermaxw300](docs/images/dcgan-losses.png)\n",
    "\n",
    "Tanto a arquitetura quanto hiperparâmetros de otimização e inicialização de pesos podem ser experimentados\n",
    "e acredita-se que existam hipóteses de modelos que fornecerão resultados melhores.\n",
    "\n",
    "\n",
    "Além disso, com a DCGAN _vanilla_ não é possível definir qual classe de imagem se deseja gerar. Para tanto,\n",
    "foram propostas as _conditional_ GANs justamente para fornecer um controle de qual classe será gerada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d144c63b-996f-47a6-8684-04331e5bf957",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Geração de um Lado dado Outro\n",
    "\n",
    "O quarto e último experimento foi feito no _notebook_ [03-side2side.ipynb](03-side2side.ipynb).\n",
    "Nele o objetivo foi de usar uma _conditional DCGAN_ para, **dada a imagem de um personagem em uma pose,\n",
    "gerar a sua imagem em outra das 3 poses restantes**.\n",
    "\n",
    "Para isso foi usada a arquitetura de redes geradoras Pix2Pix (Isola et al. 2017) com algumas adaptações.\n",
    "Assim como os demais experimentos, foi usado do _dataset_ TinyHero configurado de forma a\n",
    "estabelecer pares de imagens de personagens na pose `frente` para `direita`:\n",
    "\n",
    "![center](docs/images/tiny-hero-front-to-right.png)\n",
    "\n",
    "A rede geradora foi construída baseada no modelo U-net que reduz a dimensionalidade espacial\n",
    "da entrada até $(1, 1)$ e depois a reconstrói até o tamanho original, usando _skip connections_\n",
    "entre as camadas de redução e as de aumento.\n",
    "\n",
    "Já a rede discriminadora é uma CNN que classifica por _patches_ de $(30, 30)$ da entrada, conforme\n",
    "previsto pela arquitetura Pix2Pix.\n",
    "\n",
    "O treinamento foi feito ao longo de $100.000$ passos de processamento de _batch_ (de tamanho $1$) e os\n",
    "resultados foram bem positivos:\n",
    "\n",
    "![centermaxw700](docs/images/p2p-result-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a617bf-284b-459f-8f94-e14a450acb66",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "É interessante notar, nesse exemplo, que apenas olhando a imagem de entrada do personagem, não é possível\n",
    "inferir que ele possui cabelo, nem a presença e cor dos olhos. Mas a rede foi capaz de inferir\n",
    "esses detalhes possivelmente a partir de exemplos de outros personagens com os quais treinou.\n",
    "\n",
    "Mais exemplos:\n",
    "\n",
    "![centermaxw700](docs/images/p2p-result-2.png)\n",
    "![centermaxw700](docs/images/p2p-result-3.png)\n",
    "\n",
    "Neste último é interessante notar que a imagem gerada está mais correta do que a esperada (!!). Nitidamente,\n",
    "no _dataset_ TinyHero as poses `direita` e `esquerda` são um simples espelhamento no eixo Y. Contudo, em\n",
    "personagens sem simetria por esse eixo, o _dataset_ provê a pose `direita` ou `esquerda` incorreta. E a\n",
    "rede foi capaz de gerar uma imagem mais correta do que o próprio rótulo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}